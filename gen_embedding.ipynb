{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fa38cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import torch\n",
    "from curses import meta\n",
    "from locale import normalize\n",
    "import os.path as osp\n",
    "from typing import final\n",
    "from xxlimited import new\n",
    "import os, datetime\n",
    "import torch\n",
    "import time\n",
    "import os, datetime\n",
    "from torch_geometric.datasets import AMiner\n",
    "from tqdm import tqdm\n",
    "# import torch.multiprocessing\n",
    "# torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "from model import MetaPath2Vec # modified Metapath2vec for the path embedding generation\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f7bb9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_dir = \"/home/andrewngo/Desktop/MLTracker/model_20220217192920\"\n",
    "embedding_dir = \"/home/andrewngo/Desktop/MLTracker/model_CUC_20220311120344\" # model folder\n",
    "graph_dir = '/home/andrewngo/Desktop/MLTracker/graph_data_20220305160351'\n",
    "model = torch.load(embedding_dir + \"/model.pt\")\n",
    "data = torch.load(graph_dir + '/graph_data_torch.pt')\n",
    "metapath_strat = \"CUC\"\n",
    "metapath = model.metapath\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9cd3be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_metapath_sampling(sample=20000):\n",
    "    node_num = len(metapath) + 1\n",
    "    model_sample = MetaPath2Vec(data.edge_index_dict, embedding_dim=128,\n",
    "                        metapath=metapath, walk_length=node_num, context_size=node_num,\n",
    "                        walks_per_node=1, num_negative_samples=1,\n",
    "                        sparse=True).to(device)\n",
    "    loader_sample = model_sample.loader(batch_size=1, shuffle=False, num_workers=1)\n",
    "    optimizer = torch.optim.SparseAdam(list(model_sample.parameters()), lr=0.001)\n",
    "    print(model_sample.start)\n",
    "    print(model_sample.end)\n",
    "    model_sample.train()\n",
    "    temp = []\n",
    "    for i, (pos_rw, neg_rw) in enumerate(tqdm(loader_sample)):\n",
    "        temp.append(pos_rw.to(device)[0])\n",
    "        if i > sample:\n",
    "            break\n",
    "    path = temp\n",
    "\n",
    "    new_path = []\n",
    "    print(path[1])\n",
    "    for i in range(len(path)):\n",
    "        if int(list(path[i])[-1]) != int(list(path[i])[-2]):\n",
    "            new_path.append(path[i])\n",
    "    # print(len(new_path))\n",
    "    path = new_path\n",
    "\n",
    "\n",
    "    temp = []\n",
    "    for i in range(len(path)):\n",
    "\n",
    "\n",
    "        if len(metapath)%2 == 0:\n",
    "            temp.append(path[i][:math.ceil((len(metapath)+1)/2)])\n",
    "            temp.append(path[i][math.ceil((len(metapath)+1)/2)-1:])\n",
    "        else:\n",
    "            print(path[i][:math.ceil((len(metapath)+1)/2)])\n",
    "            temp.append(path[i][:math.ceil((len(metapath)+1)/2)])\n",
    "            temp.append(path[i][math.ceil((len(metapath)+1)/2):])\n",
    "    path = temp\n",
    "    path = list(set(path))\n",
    "    # print(path)\n",
    "    print(len(path))\n",
    "    return temp, model_sample.start, model_sample.end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53aaebd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(metapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0eeddf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/15425 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Computer': 0, 'User': 15425}\n",
      "{'Computer': 15425, 'User': 27013}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15425/15425 [00:16<00:00, 961.23it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    1, 17020,   878, 19563,  2358], device='cuda:0')\n",
      "30850\n"
     ]
    }
   ],
   "source": [
    "path, start_idx, end_idx = generate_metapath_sampling(100000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05d1cd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "metapath_strat = \"CUC\"\n",
    "def reindexing_path(model, malicious_path, path_type):\n",
    "# ''' malicious_path of each node type are arranging from 0\n",
    "# however, in metapath2vec implementation, they are convert to \n",
    "# a unique indexing (i.e, computer from 0 -> 32131, user from 32131 -> 42213). \n",
    "# This function will convert to metapath2vec reference indexing. '''\n",
    "    new_path = []\n",
    "    if path_type == \"CUC\":\n",
    "        for i in malicious_path:\n",
    "            first = i[0] + model.start[\"Computer\"]\n",
    "            sec = i[1] + model.start[\"User\"]\n",
    "            third = i[2] + model.start[\"Computer\"]\n",
    "            new_path.append((first, sec, third))\n",
    "        # print(malicious_path)\n",
    "\n",
    "    elif path_type == \"UCAC\":\n",
    "        for i in malicious_path:\n",
    "            first = i[0] + model.start[\"User\"]\n",
    "            sec = i[1] + model.start[\"Computer\"]\n",
    "            third = i[2] + model.start[\"Auth_Type\"]\n",
    "            forth = i[3] + model.start[\"Computer\"]\n",
    "            new_path.append((first, sec, third, forth))\n",
    "    elif path_type == \"UCCA\":\n",
    "        for i in malicious_path:\n",
    "            first = i[0] + model.start[\"User\"]\n",
    "            sec = i[1] + model.start[\"Computer\"]\n",
    "            third = i[2] + model.start[\"Computer\"]\n",
    "            forth = i[3] + model.start[\"Auth_Type\"]\n",
    "            new_path.append((first, sec, third, forth))\n",
    "\n",
    "    elif path_type == \"UCC\":\n",
    "        for i in malicious_path:\n",
    "            first = i[0] + model.start[\"User\"]\n",
    "            sec = i[1] + model.start[\"Computer\"]\n",
    "            third = i[2] + model.start[\"Computer\"]\n",
    "            new_path.append((first, sec, third))\n",
    "    return new_path\n",
    "\n",
    "dir_normal_path = \"/normal_path_\" + metapath_strat + \".pt\"\n",
    "normal_path = list(torch.load(graph_dir + dir_normal_path))\n",
    "normal_path = reindexing_path(model, normal_path, metapath_strat)\n",
    "normal_path_tensor = [torch.LongTensor(i).to(device) for i in normal_path]\n",
    "\n",
    "# print(normal_path_tensor[1])\n",
    "    \n",
    "dir_all_malicious_path = \"/all_malicious_path_\" + metapath_strat + \".pt\"\n",
    "all_malicious_path = list(torch.load(graph_dir + dir_all_malicious_path))\n",
    "all_malicious_path = reindexing_path(model, all_malicious_path, metapath_strat)\n",
    "all_malicious_path_tensor = [torch.LongTensor(i).to(device) for i in all_malicious_path]\n",
    "\n",
    "# print(all_malicious_path_tensor)\n",
    "\n",
    "dir_train_val_malicious_path = \"/train_val_malicious_path_\" + metapath_strat + \".pt\"\n",
    "train_val_malicious_path = list(torch.load(graph_dir + dir_train_val_malicious_path))\n",
    "train_val_malicious_path = reindexing_path(model, train_val_malicious_path, metapath_strat)\n",
    "train_val_malicious_path_tensor = [torch.LongTensor(i).to(device) for i in train_val_malicious_path]\n",
    "\n",
    "\n",
    "dir_test_malicious_path = \"/test_malicious_path_\" + metapath_strat + \".pt\"\n",
    "test_malicious_path = list(torch.load(graph_dir + dir_test_malicious_path))\n",
    "test_malicious_path = reindexing_path(model, test_malicious_path, metapath_strat)\n",
    "test_malicious_path_tensor = [torch.LongTensor(i).to(device) for i in test_malicious_path]\n",
    "\n",
    "# print(malicious_path)\n",
    "labels = [0 for i in range(len(path))] + [1 for i in range(len(all_malicious_path))]\n",
    "path = path + all_malicious_path_tensor\n",
    "\n",
    "\n",
    "out = []\n",
    "out_index_path = dict()\n",
    "for i in range(len(path)):\n",
    "    out_index_path[len(out)] = path[i]\n",
    "    out.append(model.get_embedding(path[i]))\n",
    "# print(out[path[1]].size())\n",
    "# print(out[1])\n",
    "\n",
    "\n",
    "out_normal = []\n",
    "out_normal_index_path = dict()\n",
    "for i in range(len(normal_path)):\n",
    "    out_normal_index_path[len(out_normal)] = normal_path[i]\n",
    "    out_normal.append(model.get_embedding(normal_path_tensor[i]))\n",
    "\n",
    "\n",
    "out_mal_train_val = []\n",
    "out_mal_train_val_index_path = dict()\n",
    "for i in range(len(train_val_malicious_path)):\n",
    "    out_mal_train_val_index_path[len(out_mal_train_val)] = train_val_malicious_path[i]\n",
    "    out_mal_train_val.append(model.get_embedding(train_val_malicious_path_tensor[i]))\n",
    "\n",
    "\n",
    "out_mal_test = []\n",
    "out_mal_test_index_path = dict()\n",
    "for i in range(len(test_malicious_path)):\n",
    "    out_mal_test_index_path[len(out_mal_test)] = test_malicious_path[i]\n",
    "    out_mal_test.append(model.get_embedding(test_malicious_path_tensor[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8df7d5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "588958"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out_normal_index_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "652ccebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_directory = embedding_dir\n",
    "torch.save(path, store_directory + '/path_1.pt')\n",
    "torch.save(labels, store_directory + '/path_labels_1.pt')\n",
    "\n",
    "torch.save(out, store_directory + '/out_1.pt')\n",
    "torch.save(out_index_path, store_directory + '/out_index_path_1.pt')\n",
    "\n",
    "torch.save(out_normal, store_directory + '/out_normal_1.pt')\n",
    "torch.save(out_normal_index_path, store_directory + '/out_normal_index_path_1.pt')\n",
    "\n",
    "torch.save(out_mal_train_val, store_directory + '/out_mal_train_val_1.pt')\n",
    "torch.save(out_mal_train_val_index_path, store_directory + '/out_mal_train_val_index_path_1.pt')\n",
    "\n",
    "torch.save(out_mal_test, store_directory + '/out_mal_test_1.pt')\n",
    "torch.save(out_mal_test_index_path, store_directory + '/out_mal_test_index_path_1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff83fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafb1a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
